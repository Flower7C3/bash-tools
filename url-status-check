#!/usr/bin/env bash

# HTTP status code and redirect checker
# Usage: ./url-status-check [OPTIONS] <URLs...>

set -euo pipefail

# Set terminal type for proper color support
export TERM=xterm-256color

# Main function wrapper
main() {
  # Check if common-functions exists
  if [[ ! -f "$(dirname "$0")/common-functions" ]]; then
    echo "Downloading common-functions from GitHub..."
    if ! curl -fsSL https://raw.githubusercontent.com/Flower7C3/bash-tools/master/common-functions -o "$(dirname "$0")/common-functions"; then
      echo "Failed to download common-functions"
      exit 1
    fi
  fi

  # Source common functions
  source "$(dirname "$0")/common-functions"

  # Call the actual main function
  url_main "$@"
}

url_main() {
  # Function to display usage
  function show_usage() {
    log_usage_title '[OPTIONS] <URLs...>'
    echo
    echo 'Check HTTP status codes and redirects'
    echo
    log_header 'Options'
    log_usage_options_line '-r;--max-redirects <NUM>' \
      'Maximum number of redirects to follow (default: %s)' "$DEFAULT_MAX_REDIRECTS"
    log_usage_options_line '-t;--timeout <SECONDS>' \
      'Request timeout (default: %s)' "$DEFAULT_TIMEOUT"
    log_usage_options_line '-u;--user-agent <STRING>' \
      'User agent string (default: Mozilla/5.0...)'
    log_usage_options_line '-m;--method <METHOD>' \
      'HTTP method (default: GET)'
    log_usage_options_line '-H;--header <HEADER>' \
      'Add custom header (can be used multiple times)'
    log_usage_options_line '-c;--cookies <STRING>' \
      'Cookie string'
    log_usage_options_line '-k;--insecure' \
      'Disable SSL certificate verification'
    log_usage_options_line '-f;--no-follow' \
      'Don'\''t follow redirects'
    #    log_usage_options_line '-p;--parallel' \
    #      'Enable parallel processing'
    #    log_usage_options_line '-P;--max-parallel <NUM>' \
    #      'Maximum parallel requests (default: 5)'
    log_usage_options_line '-F;--format <FORMAT>' \
      'Output format: text, json, csv (default: text)'
    log_usage_options_line '-u;--update' \
      'Update app'
    log_usage_options_line '-h;--help' \
      'Show this help message'
    echo
    log_header 'Examples'
    log_usage_example_line 'https://example.com'
    log_usage_example_line '-r 10 -t 30 https://example.com'
    log_usage_example_line '-m POST -H "Content-Type: application/json" https://api.example.com'
    log_usage_example_line '-p -P 10 urls.txt'
    log_usage_example_line '-F json -o results.json https://example.com'
    exit 0
  }

  # Default values
  DEFAULT_MAX_REDIRECTS=5
  DEFAULT_TIMEOUT=10
  DEFAULT_USER_AGENT="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:87.0) Gecko/20100101 Firefox/87.0"

  # Global variables
  MAX_REDIRECTS=$DEFAULT_MAX_REDIRECTS
  TIMEOUT=$DEFAULT_TIMEOUT
  USER_AGENT="$DEFAULT_USER_AGENT"
  FOLLOW_REDIRECTS=1
  OUTPUT_FORMAT="text"
  METHOD="GET"
  HEADERS=()
  COOKIES=""
  SSL_VERIFY=1
  #  PARALLEL=0
  #  MAX_PARALLEL=5

  # Function to check URL status
  check_url() {
    local _url="$1"
    local _redirect_count="${2:-0}"
    local _original_url="${3:-}"

    if [[ -z "$_original_url" ]]; then
      _original_url="$_url"
    fi

    # Build curl command
    local _curl_cmd="curl -s -i -k --max-time $TIMEOUT"

    # Add user agent
    _curl_cmd="$_curl_cmd -H 'User-Agent: $USER_AGENT'"

    # Add custom headers
    for header in "${HEADERS[@]}"; do
      _curl_cmd="$_curl_cmd -H '$header'"
    done

    # Add cookies
    if [[ -n "$COOKIES" ]]; then
      _curl_cmd="$_curl_cmd -H 'Cookie: $COOKIES'"
    fi

    # Add method
    if [[ "$METHOD" != "GET" ]]; then
      _curl_cmd="$_curl_cmd -X $METHOD"
    fi

    # Add SSL verification
    if [[ "$SSL_VERIFY" == "0" ]]; then
      _curl_cmd="$_curl_cmd -k"
    fi

    # Add redirect handling
    if [[ "$FOLLOW_REDIRECTS" == "0" ]]; then
      _curl_cmd="$_curl_cmd --max-redirs 0"
    else
      _curl_cmd="$_curl_cmd --max-redirs $MAX_REDIRECTS"
    fi

    # Add output format
    _curl_cmd="$_curl_cmd -o /dev/null --write-out '%{http_code}|%{redirect_url}|%{time_total}|%{size_download}|%{url_effective}'"

    # Execute curl command
    local _response
    if ! _response=$(eval "$_curl_cmd '$_url'" 2>/dev/null); then
      log_error 'Failed to check URL: <u>%s</u>' "$_url"
      return 1
    fi

    # Parse response
    IFS='|' read -r _response_code _redirect_url _time_total _size_download _url_effective <<<"$_response"

    # Output results based on format
    case "$OUTPUT_FORMAT" in
    "json")
      cat <<EOF
{
  "original_url": "$_original_url",
  "final_url": "$_url_effective",
  "status_code": $_response_code,
  "redirect_url": "$_redirect_url",
  "response_time": $_time_total,
  "content_length": $_size_download,
  "redirect_count": $_redirect_count
}
EOF
      ;;
    "csv")
      echo "$_original_url,$_url_effective,$_response_code,$_redirect_url,$_time_total,$_size_download,$_redirect_count"
      ;;
    *)
      local _message
      _message="$_url"
      if [[ -n "$_redirect_url" ]]; then
        _message="$(printf '%s â†’ %s' "$_message" "$_redirect_url")"
      fi
      local _status_note
      _status_note="$(printf '%s, %ss, %s bytes' "$_response_code" "$_time_total" "$_size_download")"
      if [[ "$_redirect_count" -gt 0 ]]; then
        _status_note="$(printf '%s, %d redirects' "$_status_note" "$_redirect_count")"
      fi
      if [[ "$_response_code" -lt 300 ]]; then
        log_success ---width 80 '%s' "$_message" ---status "$_status_note"
      elif [[ "$_response_code" -lt 400 ]]; then
        log_warning ---width 80 '%s' "$_message" ---status "$_status_note"
      elif [[ "$_response_code" -lt 500 ]]; then
        log_error ---width 80 '%s' "$_message" ---status "$_status_note"
      else
        log_info ---width 80 '%s' "$_message" ---status "$_status_note"
      fi
      ;;
    esac

    # Follow redirects if enabled and status is 3xx
    if [[ "$FOLLOW_REDIRECTS" == "1" && "$_response_code" -ge 300 && "$_response_code" -lt 400 && -n "$_redirect_url" ]]; then
      if [[ "$_redirect_count" -ge "$MAX_REDIRECTS" ]]; then
        log_warning 'Maximum redirects exceeded for %s' "$_original_url"
        return 1
      fi

      # Recursively check redirect URL
      check_url "$_redirect_url" $((_redirect_count + 1)) "$_original_url"
    fi
  }

  # Function to process URLs from file
  process_urls_from_file() {
    local _file="$1"

    if [[ ! -f "$_file" ]]; then
      log_error 'File not found: <u>%s</u>' "$_file"
      return 1
    fi

    log_info 'Processing URLs from file: <u>%s</u>' "$_file"

    # Add CSV header if output format is CSV
    if [[ "$OUTPUT_FORMAT" == "csv" ]]; then
      echo "Original URL,Final URL,Status Code,Redirect URL,Response Time,Content Length,Redirect Count"
    fi

    while IFS= read -r line; do
      # Skip empty lines and comments
      [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]] && continue

      # Trim whitespace
      line=$(echo "$line" | xargs)

      # Validate URL
      if ! validate_url "$line"; then
        continue
      fi

      # Check URL
      check_url "$line"

    done <"$_file"
  }

  # Function to process URLs in parallel
  #  process_urls_parallel() {
  #    local _urls=("$@")
  #    local _pids=()
  #    local _results=()
  #
  #    log_info 'Processing %d URLs in parallel (max: %s)' "${#_urls[@]}" "$MAX_PARALLEL"
  #
  #    for url in "${_urls[@]}"; do
  #      # Wait if we've reached max parallel processes
  #      while [[ ${#_pids[@]} -ge $MAX_PARALLEL ]]; do
  #        for i in "${!_pids[@]}"; do
  #          if ! kill -0 "${_pids[$i]}" 2>/dev/null; then
  #            unset "${_pids[$i]}"
  #          fi
  #        done
  #        sleep 0.1
  #      done
  #
  #      # Start background process
  #      check_url "$url" &
  #      _pids+=($!)
  #    done
  #
  #    # Wait for all processes to complete
  #    for pid in "${_pids[@]}"; do
  #      wait "$pid"
  #    done
  #  }

  # Function to parse command line arguments
  parse_arguments() {
    while [[ $# -gt 0 ]]; do
      case "$1" in
      -r | --max-redirects)
        MAX_REDIRECTS="$2"
        if ! [[ "$MAX_REDIRECTS" =~ ^[0-9]+$ ]] || [[ "$MAX_REDIRECTS" -lt 0 ]]; then
          log_error 'Invalid max redirects: %d' "$MAX_REDIRECTS"
          exit 1
        fi
        shift 2
        ;;
      -t | --timeout)
        TIMEOUT="$2"
        if ! [[ "$TIMEOUT" =~ ^[0-9]+$ ]] || [[ "$TIMEOUT" -lt 1 ]]; then
          log_error 'Invalid timeout: %d' "$TIMEOUT"
          exit 1
        fi
        shift 2
        ;;
      -a | --user-agent)
        USER_AGENT="$2"
        shift 2
        ;;
      -m | --method)
        METHOD="$2"
        if [[ "$METHOD" != "GET" && "$METHOD" != "POST" && "$METHOD" != "PUT" && "$METHOD" != "DELETE" && "$METHOD" != "HEAD" && "$METHOD" != "OPTIONS" ]]; then
          log_error 'Invalid HTTP method: %s' "$METHOD"
          exit 1
        fi
        shift 2
        ;;
      -H | --header)
        HEADERS+=("$2")
        shift 2
        ;;
      -c | --cookies)
        COOKIES="$2"
        shift 2
        ;;
      -k | --insecure)
        SSL_VERIFY=0
        shift
        ;;
      -f | --no-follow)
        FOLLOW_REDIRECTS=0
        shift
        ;;
        #      -p | --parallel)
        #        PARALLEL=1
        #        shift
        #        ;;
        #      -P | --max-parallel)
        #        MAX_PARALLEL="$2"
        #        if ! [[ "$MAX_PARALLEL" =~ ^[0-9]+$ ]] || [[ "$MAX_PARALLEL" -lt 1 ]]; then
        #          log_error 'Invalid max parallel: %s' "$MAX_PARALLEL"
        #          exit 1
        #        fi
        #        shift 2
        #        ;;
      -F | --format)
        OUTPUT_FORMAT="$2"
        if [[ "$OUTPUT_FORMAT" != "text" && "$OUTPUT_FORMAT" != "json" && "$OUTPUT_FORMAT" != "csv" ]]; then
          log_error 'Invalid output format: %s' "$OUTPUT_FORMAT"
          exit 1
        fi
        shift 2
        ;;
      -h | --help)
        show_usage
        ;;
      -u | --update)
        update_application
        ;;
      -*)
        log_error 'Unknown option: <b>%s</b>' "$1"
        echo
        show_usage
        ;;
      *)
        # URL argument
        if [[ -f "$1" ]]; then
          process_urls_from_file "$1"
        else
          if ! validate_url "$1"; then
            exit 1
          fi
          check_url "$1"
        fi
        shift
        ;;
      esac
    done
  }

  log_title 'URL status check'

  # Check if curl is available
  check_dependencies curl

  # If no arguments provided, show usage
  if [[ $# -eq 0 ]]; then
    log_error 'No URLs provided'
    show_usage
  fi

  # Parse arguments
  parse_arguments "$@"
}

# Run main function
main "$@"
